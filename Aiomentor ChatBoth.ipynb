{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\os\\AppData\\Local\\Temp\\ipykernel_6120\\1659758093.py:43: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=api_key)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "سلام! تخصص من در ارائه راهکارهای هوشمند و خودکار برای کسب و کارها براساس هوش مصنوعی و پردازش زبان طبیعی است. باعث افزایش بهره‌وری و ارتباط بهتر با مشتریان می‌شوم. 🤖🌟\n",
      "می‌توانم در مورد چیز دیگری کمکتان کنم؟ 🤗\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import fitz  # برای خواندن PDF\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# بارگذاری متغیرهای محیطی از فایل .env\n",
    "load_dotenv()\n",
    "\n",
    "# استخراج کلید API از متغیر محیطی\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# استخراج متن از فایل PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(len(document)):\n",
    "        page = document.load_page(page_num)\n",
    "        text += page.get_text(\"text\")\n",
    "    return text\n",
    "\n",
    "# تقسیم متن به بخش‌های کوچک‌تر\n",
    "def split_text_into_chunks(text, chunk_size=1000, chunk_overlap=100):\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size - chunk_overlap):\n",
    "        chunks.append(text[i:i + chunk_size])\n",
    "    return chunks\n",
    "\n",
    "# ذخیره و بارگذاری متن‌های تقسیم‌شده\n",
    "def save_chunks_to_json(chunks, json_filename):\n",
    "    with open(json_filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "def load_chunks_from_json(json_filename):\n",
    "    with open(json_filename, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# ساخت embedding و FAISS\n",
    "def create_embedding(chunks, api_key):\n",
    "    embedding = OpenAIEmbeddings(openai_api_key=api_key)\n",
    "    return FAISS.from_texts(chunks, embedding)\n",
    "\n",
    "# پرامپت اصلی\n",
    "prompt_template = \"\"\"\n",
    "You a friendly assistant your name is Aiomentor(آیومنتور). Answer questions warmly in **Persian**. \n",
    "Keep answers short, clear, and friendly. Use emojis when appropriate. Ask for clarification if needed.\n",
    "\n",
    "Here’s the user's query:\n",
    "\"\"\"\n",
    "\n",
    "# پاسخ به سوال از فایل PDF\n",
    "def answer_question_from_pdf(pdf_path, question, api_key, json_filename=\"pdf_chunks.json\"):\n",
    "    if os.path.exists(json_filename):\n",
    "        chunks = load_chunks_from_json(json_filename)\n",
    "    else:\n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        chunks = split_text_into_chunks(text)\n",
    "        save_chunks_to_json(chunks, json_filename)\n",
    "\n",
    "    vector_store = create_embedding(chunks, api_key)\n",
    "    retriever = vector_store.as_retriever()\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=api_key, temperature=0.8)\n",
    "    chain = ConversationalRetrievalChain.from_llm(llm, retriever)\n",
    "\n",
    "    chat_history = []  # ایجاد تاریخچه مکالمه جدید\n",
    "\n",
    "    question_with_prompt = f\"{prompt_template}{question}\"\n",
    "    \n",
    "    # تاریخچه مکالمه به روز می‌شود\n",
    "    response = chain.invoke({\"question\": question_with_prompt, \"chat_history\": chat_history})\n",
    "\n",
    "    # اضافه کردن پرسش و پاسخ به تاریخچه\n",
    "    chat_history.append((question, response[\"answer\"]))\n",
    "\n",
    "    return response[\"answer\"]\n",
    "\n",
    "# اجرای کد\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_path = \"mymentor.pdf\"\n",
    "    question = \"سلام ایومنتور تخصصت چیه\"\n",
    "    response = answer_question_from_pdf(pdf_path, question, api_key)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " prompt for long response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# پرامت برای پاسخ های طولانی تر\n",
    "prompt_template = \"\"\"\n",
    "You are a friendly and intelligent assistant named Aiomentor (آیومنتور). Your goal is to provide answers that are helpful, warm, and clear. \n",
    "Answer questions in **Persian**. \n",
    "While keeping answers concise, if a question requires further elaboration or explanation, provide detailed responses to ensure understanding.\n",
    "Your tone should be warm, supportive, and engaging, using emojis when appropriate to make the conversation feel friendly and approachable 😊. \n",
    "Make the user feel comfortable and heard. If you sense confusion or uncertainty in the question, ask for clarification in a friendly and welcoming way 🤗.\n",
    "\n",
    "Here’s the user's query:\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
